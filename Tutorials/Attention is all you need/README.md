<p align="center">
  <img src="https://media3.giphy.com/media/fnJYeEuMcrIgFFgNAW/giphy.gif?cid=ecf05e47up8ipf9oqwbhwcjp2pz2zzx0k5zvn3voiamk820t&rid=giphy.gif" />
</p>
  
  <p align="center">
  <img src="https://media.tenor.com/images/e1d0f582eea7f610b272b0dc1b6272d8/tenor.gif">
</p>

# Attention Is All You Need


Main notebook links:

<a href="https://colab.research.google.com/drive/1fvNDcXSVVAS22TTpfrJIvpSr_xybbQuO?usp=sharing">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
 <t/>

<a href="https://www.kaggle.com/simarpreetsingh019/attention-is-all-you-need-ipynb">
  <img src="https://www.vectorlogo.zone/logos/kaggle/kaggle-ar21.svg" alt="Open In kaggle"/>
</a>

 This model is based solely on attention mechanisms and introduces Multi-Head Attention. The encoder and decoder are made of multiple layers, with each layer consisting of Multi-Head Attention and Positionwise Feedforward sublayers. This model is currently used in many state-of-the-art sequence-to-sequence and transfer learning tasks.
 
 All working and Explaination is provided in Notebook itself.
 

For Research paper , [click here](https://arxiv.org/abs/1706.03762 "Research paper")

This notebook is made with help from @bentrevett's [Bentrevett pytorch-seq2seq](https://github.com/bentrevett/pytorch-seq2seq) notebook

